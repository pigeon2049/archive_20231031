# Tesla wins another court case by arguing fatal Autopilot crash was caused by human error
**Andrew J. Hawkins**

**2023-10-31 18:25**

**https://www.theverge.com/2023/10/31/23940693/tesla-jury-autopilot-win-liable-micah-lee**

Family of 37-year-old Micah Lee, who died when his Model 3 hit a tree in 2019, argued that the company was liable because it knowingly sold a defective product.
----------------------------------------------------------------------------------------------------------------------------------------------------------------

![](https://cdn.vox-cdn.com/thumbor/Kgn3DVu5oEsydPythl8NEL3XYVg=/0x0:2040x1360/1200x628/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/11423499/acastro_180524_1777_tesla_0002.jpg)

Tesla was found not to be liable for the death of a Model 3 owner who’s vehicle crashed while driving in Autopilot, a jury decided Tuesday.

The case centered on a crash in California in 2019, in which a Tesla Model 3 veered off the road, crashing into a palm tree before catching fire. The crash killed the driver, 37-year-old Micah Lee, who was reportedly using Autpilot at the time of the incident. Lee’s family, who were passengers in the vehicle, accused Tesla of knowing that Autopilot was defective when it sold them the car.

The case centered on a crash in California in 2019

But in a 9-to-3 decision, the California jury found in favor of Tesla, [Reuters reports](https://www.reuters.com/business/autos-transportation/tesla-wins-autopilot-trial-involving-fatal-crash-2023-10-31/). Tesla’s lawyers argued that the crash was caused by human error.

It was Tesla’s second victory in a series of cases arguing that the company should be held liable when its vehicles crash while using advanced driver assist systems like Autopilot. Earlier this year, [a jury ruled against plaintiff Justine Hsu](https://www.theverge.com/2023/4/21/23693482/tesla-lawsuit-blamed-autopilot-crash), who sued Tesla after his vehicle hit a median while using Autopilot.

The case brought by Lee’s family, however, was the first to center on a fatal crash involving Autopilot. And the result comes as Tesla finds itself under increased scrutiny from federal and state regulators around its partially autonomous technology.

Tesla is under criminal investigation by [the US Department of Justice](https://www.theverge.com/2022/10/26/23425335/tesla-autopilot-justice-department-criminal-investigation) for its self-driving features. In 2021, the US National Highway Traffic Safety Administration (NHTSA) launched [a probe](https://www.theverge.com/2021/8/16/22626819/tesla-autopilot-crash-emergency-vehicle-probe-nhtsa) regarding Autopilot following many crashes with parked emergency vehicles. And California’s Department of Motor Vehicles has accused Tesla of making [false claims](https://www.theverge.com/2022/8/6/23294658/california-dmv-accuses-tesla-false-claims-autopilot-full-self-driving-autonomous-vehicles) about its Autopilot and Full Self-Driving (FSD) capabilities.

Earlier this month, Tesla CEO Elon Musk laughed off a question as to whether his company would accept legal liability for its self-driving vehicles in the future. “There’s a lot of people who assume we have legal liability,” Musk said, “judging by the lawsuits.”

Comments